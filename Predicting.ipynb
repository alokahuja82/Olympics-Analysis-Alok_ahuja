{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "df = pd.read_csv('athlete_events.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ID',\n",
       " 'Name',\n",
       " 'Sex',\n",
       " 'Age',\n",
       " 'Height',\n",
       " 'Weight',\n",
       " 'Team',\n",
       " 'NOC',\n",
       " 'Games',\n",
       " 'Year',\n",
       " 'Season',\n",
       " 'City',\n",
       " 'Sport',\n",
       " 'Event',\n",
       " 'Medal']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99041, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered = df[['Name','Sport','Height','Weight','Sex']]\n",
    "df_grouped = df_filtered.dropna().groupby('Name').first().reset_index()\n",
    "df_grouped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_grouped.Sport.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a one'hot encode of the Sport feature\n",
    "df_one_hot_encode = pd.get_dummies(df_grouped.Sport,prefix='sport', drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the other features\n",
    "df_one_hot_encode['Height'] = df_grouped.Height\n",
    "df_one_hot_encode['Weight'] = df_grouped.Weight\n",
    "df_one_hot_encode['Sex'] = df_grouped.Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_one_hot_encode.loc[df_one_hot_encode.Sex.isin(['M']),'sex']= 0\n",
    "df_one_hot_encode.loc[df_one_hot_encode.Sex.isin(['F']),'sex']= 1\n",
    "df_one_hot_encode = df_one_hot_encode.drop(columns='Sex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: 99041\n",
      "0.0    69389\n",
      "1.0    29652\n",
      "Name: sex, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape: \" + str(df_one_hot_encode.shape[0]))\n",
    "print(df_one_hot_encode.sex.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((96000, 2), (96000, 2))\n",
      "(96000, 8)\n"
     ]
    }
   ],
   "source": [
    "# further processing \n",
    "train_data = df_one_hot_encode[:NUM_TRAIN_DATA]\n",
    "#train_data_female = df_one_hot_encode[:NUM_TRAIN_DATA][df_one_hot_encode.sex==0]\n",
    "test_data = df_one_hot_encode[NUM_TRAIN_DATA:]\n",
    "\n",
    "# Preparing Dataset for consumption.\n",
    "\n",
    "model_input = train_data.iloc[:, -3:-1].values\n",
    "labels = np.asarray([[i[0], 1 - i[0]] for i in train_data.iloc[:, -1:].values])\n",
    "print(model_input.shape, labels.shape)\n",
    "\n",
    "validation_features = test_data.iloc[:, -3:-1].values\n",
    "validation_labels = [[i[0], 1 - i[0]] for i in test_data.iloc[:, -1:].values]\n",
    "\n",
    "\n",
    "def normalize(v):\n",
    "    m = np.mean(v)\n",
    "    std = np.std(v)\n",
    "    return (v-m)/std\n",
    "\n",
    "def np_power(v, power):\n",
    "    for _ in range(power):\n",
    "        v*=v\n",
    "    return v\n",
    "\n",
    "def feature_generator(model_input):\n",
    "    return np.transpose([np.transpose(normalize(model_input[:,0])),\n",
    "                         np.transpose(normalize(model_input[:,1])),\n",
    "                         np.transpose(normalize(model_input[:,0]/model_input[:,1])),\n",
    "                         np.transpose(normalize(model_input[:,0]*model_input[:,1])),\n",
    "                         np.transpose(normalize(np_power(model_input[:,0],2))),\n",
    "                         np.transpose(normalize(np_power(model_input[:,1],2))),\n",
    "                         np.transpose(normalize(np_power(model_input[:,0],3))),\n",
    "                         np.transpose(normalize(np_power(model_input[:,1],3))),\n",
    "                         ])\n",
    "\n",
    "model_input_normalized = feature_generator(model_input)\n",
    "validation_features_normalized = feature_generator(validation_features)\n",
    "\n",
    "print(model_input_normalized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin Machine Learning\n",
    "NUM_TRAIN_DATA = 96000\n",
    "NUM_INPUTS = model_input_normalized.shape[1]\n",
    "NUM_OUTPUTS = 2\n",
    "LEARNING_RATE = 0.01\n",
    "\n",
    "#initialize weights\n",
    "weights = tf.Variable(tf.random_normal([NUM_INPUTS, NUM_OUTPUTS]))\n",
    "biases = tf.Variable(tf.random_normal([NUM_OUTPUTS]))\n",
    "\n",
    "net_input = tf.placeholder(tf.float32, [None, NUM_INPUTS])\n",
    "\n",
    "def regression(x, weights, biases):\n",
    "    affine = tf.matmul(x, weights) + biases\n",
    "    return tf.nn.softmax(affine)\n",
    "\n",
    "y_hat = regression(net_input, weights, biases)\n",
    "y_true = tf.placeholder(tf.float32, [None, NUM_OUTPUTS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true, logits=y_hat)\n",
    "cost = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(cross_entropy)\n",
    "\n",
    "\n",
    "correctly_predicted = tf.equal(tf.argmax(y_hat, 1), tf.argmax(y_true, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correctly_predicted, \"float\"))\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.70240625% male class imbalance\n"
     ]
    }
   ],
   "source": [
    "# Equivalent to value counts for binary features\n",
    "f, m = np.sum(labels, axis = 0)\n",
    "print(\"{}% male class imbalance\".format(m/(f+m)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy\n",
      "0.76192\n",
      "Validation Accuracy\n",
      "0.760934\n",
      "Validation Accuracy\n",
      "0.760605\n",
      "Validation Accuracy\n",
      "0.760605\n",
      "Validation Accuracy\n",
      "0.760934\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "n_epochs = 5\n",
    "\n",
    "for epoch_i in range(n_epochs):\n",
    "    for batch_i in range(NUM_TRAIN_DATA // batch_size):\n",
    "        index = batch_i*batch_size\n",
    "        batch_xs = model_input_normalized[index:index+batch_size]\n",
    "        batch_ys = labels[index:index+batch_size]\n",
    "        sess.run(optimizer, feed_dict={\n",
    "            net_input: batch_xs,\n",
    "            y_true: batch_ys\n",
    "        })\n",
    "    print('Validation Accuracy')\n",
    "    print(sess.run(accuracy,\n",
    "                   feed_dict={\n",
    "                       net_input: validation_features_normalized,\n",
    "                       y_true: validation_labels\n",
    "                   }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
